{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归的 Gluon 实现\n",
    "\n",
    "随着深度学习框架的发展，开发深度学习应用变得越来越便利。实践中，我们通常可以用比上一节中更简洁的代码来实现同样的模型。本节中，我们将介绍如何使用 MXNet 提供的 Gluon 接口更方便地实现线性回归的训练。\n",
    "\n",
    "## 生成数据集\n",
    "\n",
    "我们生成与上一节中相同的数据集。其中`features`是训练数据特征，`labels`是标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import autograd, nd\n",
    "\n",
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "features = nd.random.normal(scale=1, shape=(num_examples, num_inputs))\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += nd.random.normal(scale=0.01, shape=labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据\n",
    "\n",
    "Gluon 提供了`data`模块来读取数据。由于`data`常用作变量名，我们将导入的`data`模块用添加了 Gluon 首字母的假名`gdata`代替。在每一次迭代中，我们将随机读取包含 10 个数据样本的小批量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import data as gdata\n",
    "\n",
    "batch_size = 10\n",
    "# 将训练数据的特征和标签组合。\n",
    "dataset = gdata.ArrayDataset(features, labels)\n",
    "# 随机读取小批量。\n",
    "data_iter = gdata.DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里`data_iter`的使用跟上一节中的一样。让我们读取并打印第一个小批量数据样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ -5.42003720e-04  -4.72701073e-01]\n",
      " [  1.74664640e+00   4.39285845e-01]\n",
      " [  2.79939681e-01  -2.17812824e+00]\n",
      " [  6.50739193e-01  -1.14641559e+00]\n",
      " [  5.36511958e-01   5.02119362e-01]\n",
      " [ -1.73355961e+00   1.74691153e+00]\n",
      " [ -5.46343863e-01   1.49244428e+00]\n",
      " [ -6.45869493e-01  -8.86404574e-01]\n",
      " [ -6.36486828e-01   8.37802768e-01]\n",
      " [ -2.95661032e-01  -3.67180735e-01]]\n",
      "<NDArray 10x2 @cpu(0)> \n",
      "[  5.80794668   6.18776655  12.16519737   9.40812778   3.56629658\n",
      "  -5.20923519  -1.9613179    5.92847013   0.08166366   4.8691144 ]\n",
      "<NDArray 10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter:\n",
    "    print(X, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "\n",
    "在上一节从零开始的实现中，我们需要定义模型参数，并使用它们一步步描述模型是怎样计算的。当模型结构变得更复杂时，这些步骤将变得更加繁琐。其实，Gluon 提供了大量预定义的层，这使我们只需关注使用哪些层来构造模型。下面将介绍如何使用 Gluon 更简洁地定义线性回归。\n",
    "\n",
    "首先，导入`nn`模块。实际上，“nn”是 neural networks（神经网络）的缩写。顾名思义，该模块定义了大量神经网络的层。我们先定义一个模型变量`net`，它是一个 Sequential 实例。在 Gluon 中，Sequential 实例可以看作是一个串联各个层的容器。在构造模型时，我们在该容器中依次添加层。当给定输入数据时，容器中的每一层将依次计算并将输出作为下一层的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "\n",
    "net = nn.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回顾图 3.1 中线性回归在神经网络图中的表示。作为一个单层神经网络，线性回归输出层中的神经元和输入层中各个输入完全连接。因此，线性回归的输出层又叫全连接层。在 Gluon 中，全连接层是一个`Dense`实例。我们定义该层输出个数为 1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.add(nn.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "值得一提的是，在 Gluon 中我们无需指定每一层输入的形状，例如线性回归的输入个数。当模型看见数据时，例如后面执行`net(X)`时，模型将自动推断出每一层的输入个数。我们将在之后“深度学习计算”一章详细介绍这个机制。Gluon 的这一设计为模型开发带来便利。\n",
    "\n",
    "\n",
    "## 初始化模型参数\n",
    "\n",
    "在使用`net`前，我们需要初始化模型参数，例如线性回归模型中的权重和偏差。我们从 MXNet 导入`initializer`模块。该模块提供了模型参数初始化的各种方法。这里的`init`是`initializer`的缩写形式。我们通过`init.Normal(sigma=0.01)`指定权重参数每个元素将在初始化时随机采样于均值为 0 标准差为 0.01 的正态分布。偏差参数默认会初始化为零。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import init\n",
    "\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数\n",
    "\n",
    "在 Gluon 中，`loss`模块定义了各种损失函数。我们用假名`gloss`代替导入的`loss`模块，并直接使用它所提供的平方损失作为模型的损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import loss as gloss\n",
    "\n",
    "loss = gloss.L2Loss()  # 平方损失又称 L2 范数损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义优化算法\n",
    "\n",
    "同样，我们也无需实现小批量随机梯度下降。在导入 Gluon 后，我们创建一个`Trainer`实例，并指定学习率为 0.03 的小批量随机梯度下降（`sgd`）为优化算法。该优化算法将用来迭代`net`实例所有通过`add`函数嵌套的层所包含的全部参数。这些参数可以通过`collect_params`函数获取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.003})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "\n",
    "在使用 Gluon 训练模型时，我们通过调用`Trainer`实例的`step`函数来迭代模型参数。上一节中我们提到，由于变量`l`是长度为`batch_size`的一维 NDArray，执行`l.backward()`等价于执行`l.sum().backward()`。按照小批量随机梯度下降的定义，我们在`step`函数中指明批量大小，从而对批量中样本梯度求平均。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.035050\n",
      "epoch 2, loss: 0.000122\n",
      "epoch 3, loss: 0.000049\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        with autograd.record():\n",
    "            l = loss(net(X), y)\n",
    "        l.backward()\n",
    "        trainer.step(1)\n",
    "    l = loss(net(features), labels)\n",
    "    print('epoch %d, loss: %f' % (epoch, l.mean().asnumpy()))\n",
    "    if l.mean().asnumpy() < 0.00005:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们分别比较学到的和真实的模型参数。我们从`net`获得需要的层，并访问其权重（`weight`）和偏差（`bias`）。学到的和真实的参数很接近。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, -3.4], \n",
       " [[ 1.99967241 -3.40057826]]\n",
       " <NDArray 1x2 @cpu(0)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = net[0]\n",
    "true_w, dense.weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.2, \n",
       " [ 4.19966698]\n",
       " <NDArray 1 @cpu(0)>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_b, dense.bias.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.00578294 -0.01616663]]\n",
       "<NDArray 1x2 @cpu(0)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.weight.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module mxnet.gluon.loss in mxnet.gluon:\n",
      "\n",
      "NAME\n",
      "    mxnet.gluon.loss - losses for training neural networks\n",
      "\n",
      "CLASSES\n",
      "    mxnet.gluon.block.HybridBlock(mxnet.gluon.block.Block)\n",
      "        Loss\n",
      "            CTCLoss\n",
      "            CosineEmbeddingLoss\n",
      "            HingeLoss\n",
      "            HuberLoss\n",
      "            KLDivLoss\n",
      "            L1Loss\n",
      "            L2Loss\n",
      "            LogisticLoss\n",
      "            PoissonNLLLoss\n",
      "            SigmoidBinaryCrossEntropyLoss\n",
      "            SoftmaxCrossEntropyLoss\n",
      "            SquaredHingeLoss\n",
      "            TripletLoss\n",
      "    \n",
      "    class CTCLoss(Loss)\n",
      "     |  Connectionist Temporal Classification Loss.\n",
      "     |  \n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  layout : str, default 'NTC'\n",
      "     |      Layout of prediction tensor. 'N', 'T', 'C' stands for batch size,\n",
      "     |      sequence length, and alphabet_size respectively.\n",
      "     |  label_layout : str, default 'NT'\n",
      "     |      Layout of the labels. 'N', 'T' stands for batch size, and sequence\n",
      "     |      length respectively.\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**: unnormalized prediction tensor (before softmax).\n",
      "     |        Its shape depends on `layout`. If `layout` is 'TNC', pred\n",
      "     |        should have shape `(sequence_length, batch_size, alphabet_size)`.\n",
      "     |        Note that in the last dimension, index `alphabet_size-1` is reserved\n",
      "     |        for internal use as blank label. So `alphabet_size` is one plus the\n",
      "     |        actual alphabet size.\n",
      "     |  \n",
      "     |      - **label**: zero-based label tensor. Its shape depends on `label_layout`.\n",
      "     |        If `label_layout` is 'TN', `label` should have shape\n",
      "     |        `(label_sequence_length, batch_size)`.\n",
      "     |  \n",
      "     |      - **pred_lengths**: optional (default None), used for specifying the\n",
      "     |        length of each entry when different `pred` entries in the same batch\n",
      "     |        have different lengths. `pred_lengths` should have shape `(batch_size,)`.\n",
      "     |  \n",
      "     |      - **label_lengths**: optional (default None), used for specifying the\n",
      "     |        length of each entry when different `label` entries in the same batch\n",
      "     |        have different lengths. `label_lengths` should have shape `(batch_size,)`.\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: output loss has shape `(batch_size,)`.\n",
      "     |  \n",
      "     |  \n",
      "     |  **Example**: suppose the vocabulary is `[a, b, c]`, and in one batch we\n",
      "     |  have three sequences 'ba', 'cbb', and 'abac'. We can index the labels as\n",
      "     |  `{'a': 0, 'b': 1, 'c': 2, blank: 3}`. Then `alphabet_size` should be 4,\n",
      "     |  where label 3 is reserved for internal use by `CTCLoss`. We then need to\n",
      "     |  pad each sequence with `-1` to make a rectangular `label` tensor::\n",
      "     |  \n",
      "     |      [[1, 0, -1, -1],\n",
      "     |       [2, 1,  1, -1],\n",
      "     |       [0, 1,  0,  2]]\n",
      "     |  \n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |      `Connectionist Temporal Classification: Labelling Unsegmented\n",
      "     |      Sequence Data with Recurrent Neural Networks\n",
      "     |      <http://www.cs.toronto.edu/~graves/icml_2006.pdf>`_\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CTCLoss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, layout='NTC', label_layout='NT', weight=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, label, pred_lengths=None, label_lengths=None, sample_weight=None)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    class CosineEmbeddingLoss(Loss)\n",
      "     |  For a target label 1 or -1, vectors input1 and input2, the function computes the cosine distance\n",
      "     |  between the vectors. This can be interpreted as how similar/dissimilar two input vectors are.\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      L = \\sum_i \\begin{cases} 1 - {cos\\_sim({input1}_i, {input2}_i)} & \\text{ if } {label}_i = 1\\\\\n",
      "     |                       {cos\\_sim({input1}_i, {input2}_i)} & \\text{ if } {label}_i = -1 \\end{cases}\\\\\n",
      "     |      cos\\_sim(input1, input2) = \\frac{{input1}_i.{input2}_i}{||{input1}_i||.||{input2}_i||}\n",
      "     |  \n",
      "     |  `input1`, `input2` can have arbitrary shape as long as they have the same number of elements.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  margin : float\n",
      "     |      Margin of separation between correct and incorrect pair.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **input1**: a tensor with arbitrary shape\n",
      "     |      - **input2**: another tensor with same shape as pred to which input1 is\n",
      "     |        compared for similarity and loss calculation\n",
      "     |      - **label**: A 1-D tensor indicating for each pair input1 and input2, target label is 1 or -1\n",
      "     |      - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
      "     |        to the same shape as input1. For example, if input1 has shape (64, 10)\n",
      "     |        and you want to weigh each sample in the batch separately,\n",
      "     |        sample_weight should have shape (64, 1).\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: The loss tensor with shape (batch_size,).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CosineEmbeddingLoss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, weight=None, batch_axis=0, margin=0, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, input1, input2, label, sample_weight=None)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    class HingeLoss(Loss)\n",
      "     |  Calculates the hinge loss function often used in SVMs:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |      L = \\sum_i max(0, {margin} - {pred}_i \\cdot {label}_i)\n",
      "     |  \n",
      "     |  where `pred` is the classifier prediction and `label` is the target tensor\n",
      "     |  containing values -1 or 1. `pred` and `label` must have the same number of\n",
      "     |  elements.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  margin : float\n",
      "     |      The margin in hinge loss. Defaults to 1.0\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**: prediction tensor with arbitrary shape.\n",
      "     |      - **label**: truth tensor with values -1 or 1. Must have the same size\n",
      "     |        as pred.\n",
      "     |      - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
      "     |        to the same shape as pred. For example, if pred has shape (64, 10)\n",
      "     |        and you want to weigh each sample in the batch separately,\n",
      "     |        sample_weight should have shape (64, 1).\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: loss tensor with shape (batch_size,). Dimenions other than\n",
      "     |        batch_axis are averaged out.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      HingeLoss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, margin=1, weight=None, batch_axis=0, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, label, sample_weight=None)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    class HuberLoss(Loss)\n",
      "     |  Calculates smoothed L1 loss that is equal to L1 loss if absolute error\n",
      "     |  exceeds rho but is equal to L2 loss otherwise. Also called SmoothedL1 loss.\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |      L = \\sum_i \\begin{cases} \\frac{1}{2 {rho}} ({pred}_i - {label}_i)^2 &\n",
      "     |                         \\text{ if } |{pred}_i - {label}_i| < {rho} \\\\\n",
      "     |                         |{pred}_i - {label}_i| - \\frac{{rho}}{2} &\n",
      "     |                         \\text{ otherwise }\n",
      "     |          \\end{cases}\n",
      "     |  \n",
      "     |  `pred` and `label` can have arbitrary shape as long as they have the same\n",
      "     |  number of elements.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  rho : float, default 1\n",
      "     |      Threshold for trimmed mean estimator.\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**: prediction tensor with arbitrary shape\n",
      "     |      - **label**: target tensor with the same size as pred.\n",
      "     |      - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
      "     |        to the same shape as pred. For example, if pred has shape (64, 10)\n",
      "     |        and you want to weigh each sample in the batch separately,\n",
      "     |        sample_weight should have shape (64, 1).\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: loss tensor with shape (batch_size,). Dimenions other than\n",
      "     |        batch_axis are averaged out.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      HuberLoss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, rho=1, weight=None, batch_axis=0, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, label, sample_weight=None)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    class KLDivLoss(Loss)\n",
      "     |  The Kullback-Leibler divergence loss.\n",
      "     |  \n",
      "     |  KL divergence measures the distance between contiguous distributions. It\n",
      "     |  can be used to minimize information loss when approximating a distribution.\n",
      "     |  If `from_logits` is True (default), loss is defined as:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      L = \\sum_i {label}_i * \\big[\\log({label}_i) - {pred}_i\\big]\n",
      "     |  \n",
      "     |  If `from_logits` is False, loss is defined as:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      \\DeclareMathOperator{softmax}{softmax}\n",
      "     |  \n",
      "     |      prob = \\softmax({pred})\n",
      "     |  \n",
      "     |      L = \\sum_i {label}_i * \\big[\\log({label}_i) - log({pred}_i)\\big]\n",
      "     |  \n",
      "     |  \n",
      "     |  `pred` and `label` can have arbitrary shape as long as they have the same\n",
      "     |  number of elements.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  from_logits : bool, default is `True`\n",
      "     |      Whether the input is log probability (usually from log_softmax) instead\n",
      "     |      of unnormalized numbers.\n",
      "     |  axis : int, default -1\n",
      "     |      The dimension along with to compute softmax. Only used when `from_logits`\n",
      "     |      is False.\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**: prediction tensor with arbitrary shape. If `from_logits` is\n",
      "     |        True, `pred` should be log probabilities. Otherwise, it should be\n",
      "     |        unnormalized predictions, i.e. from a dense layer.\n",
      "     |      - **label**: truth tensor with values in range `(0, 1)`. Must have\n",
      "     |        the same size as `pred`.\n",
      "     |      - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
      "     |        to the same shape as pred. For example, if pred has shape (64, 10)\n",
      "     |        and you want to weigh each sample in the batch separately,\n",
      "     |        sample_weight should have shape (64, 1).\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: loss tensor with shape (batch_size,). Dimenions other than\n",
      "     |        batch_axis are averaged out.\n",
      "     |  \n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |      `Kullback-Leibler divergence\n",
      "     |      <https://en.wikipedia.org/wiki/Kullback-Leibler_divergence>`_\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      KLDivLoss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, from_logits=True, axis=-1, weight=None, batch_axis=0, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, label, sample_weight=None)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    class L1Loss(Loss)\n",
      "     |  Calculates the mean absolute error between `pred` and `label`.\n",
      "     |  \n",
      "     |  .. math:: L = \\sum_i \\vert {pred}_i - {label}_i \\vert.\n",
      "     |  \n",
      "     |  `pred` and `label` can have arbitrary shape as long as they have the same\n",
      "     |  number of elements.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**: prediction tensor with arbitrary shape\n",
      "     |      - **label**: target tensor with the same size as pred.\n",
      "     |      - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
      "     |        to the same shape as pred. For example, if pred has shape (64, 10)\n",
      "     |        and you want to weigh each sample in the batch separately,\n",
      "     |        sample_weight should have shape (64, 1).\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: loss tensor with shape (batch_size,). Dimenions other than\n",
      "     |        batch_axis are averaged out.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      L1Loss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, weight=None, batch_axis=0, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, label, sample_weight=None)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    class L2Loss(Loss)\n",
      "     |  Calculates the mean squared error between `pred` and `label`.\n",
      "     |  \n",
      "     |  .. math:: L = \\frac{1}{2} \\sum_i \\vert {pred}_i - {label}_i \\vert^2.\n",
      "     |  \n",
      "     |  `pred` and `label` can have arbitrary shape as long as they have the same\n",
      "     |  number of elements.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**: prediction tensor with arbitrary shape\n",
      "     |      - **label**: target tensor with the same size as pred.\n",
      "     |      - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
      "     |        to the same shape as pred. For example, if pred has shape (64, 10)\n",
      "     |        and you want to weigh each sample in the batch separately,\n",
      "     |        sample_weight should have shape (64, 1).\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: loss tensor with shape (batch_size,). Dimenions other than\n",
      "     |        batch_axis are averaged out.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      L2Loss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, weight=1.0, batch_axis=0, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, label, sample_weight=None)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    class LogisticLoss(Loss)\n",
      "     |  Calculates the logistic loss (for binary losses only):\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |      L = \\sum_i \\log(1 + \\exp(- {pred}_i \\cdot {label}_i))\n",
      "     |  \n",
      "     |  where `pred` is the classifier prediction and `label` is the target tensor\n",
      "     |  containing values -1 or 1 (0 or 1 if `label_format` is binary).\n",
      "     |  `pred` and `label` can have arbitrary shape as long as they have the same number of elements.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  label_format : str, default 'signed'\n",
      "     |      Can be either 'signed' or 'binary'. If the label_format is 'signed', all label values should\n",
      "     |      be either -1 or 1. If the label_format is 'binary', all label values should be either\n",
      "     |      0 or 1.\n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**: prediction tensor with arbitrary shape.\n",
      "     |      - **label**: truth tensor with values -1/1 (label_format is 'signed')\n",
      "     |        or 0/1 (label_format is 'binary'). Must have the same size as pred.\n",
      "     |      - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
      "     |        to the same shape as pred. For example, if pred has shape (64, 10)\n",
      "     |        and you want to weigh each sample in the batch separately,\n",
      "     |        sample_weight should have shape (64, 1).\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: loss tensor with shape (batch_size,). Dimenions other than\n",
      "     |        batch_axis are averaged out.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LogisticLoss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, weight=None, batch_axis=0, label_format='signed', **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, label, sample_weight=None)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    class Loss(mxnet.gluon.block.HybridBlock)\n",
      "     |  Base class for loss.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, weight, batch_axis, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, x, *args, **kwargs)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    class PoissonNLLLoss(Loss)\n",
      "     |  For a target (Random Variable) in a Poisson distribution, the function calculates the Negative\n",
      "     |  Log likelihood loss.\n",
      "     |  PoissonNLLLoss measures the loss accrued from a poisson regression prediction made by the model.\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |      L = \\text{pred} - \\text{target} * \\log(\\text{pred}) +\\log(\\text{target!})\n",
      "     |  \n",
      "     |  `pred`, `target` can have arbitrary shape as long as they have the same number of elements.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  from_logits : boolean, default True\n",
      "     |      indicating whether log(predicted) value has already been computed. If True, the loss is computed as\n",
      "     |      :math:`\\exp(\\text{pred}) - \\text{target} * \\text{pred}`, and if False, then loss is computed as\n",
      "     |      :math:`\\text{pred} - \\text{target} * \\log(\\text{pred}+\\text{epsilon})`.The default value\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  compute_full: boolean, default False\n",
      "     |      Indicates whether to add an approximation(Stirling factor) for the Factorial term in the formula for the loss.\n",
      "     |      The Stirling factor is:\n",
      "     |      :math:`\\text{target} * \\log(\\text{target}) - \\text{target} + 0.5 * \\log(2 * \\pi * \\text{target})`\n",
      "     |  epsilon: float, default 1e-08\n",
      "     |      This is to avoid calculating log(0) which is not defined.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**:   Predicted value\n",
      "     |      - **target**: Random variable(count or number) which belongs to a Poisson distribution.\n",
      "     |      - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
      "     |        to the same shape as pred. For example, if pred has shape (64, 10)\n",
      "     |        and you want to weigh each sample in the batch separately,\n",
      "     |        sample_weight should have shape (64, 1).\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: Average loss (shape=(1,1)) of the loss tensor with shape (batch_size,).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PoissonNLLLoss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, weight=None, from_logits=True, batch_axis=0, compute_full=False, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, target, sample_weight=None, epsilon=1e-08)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    SigmoidBCELoss = class SigmoidBinaryCrossEntropyLoss(Loss)\n",
      "     |  The cross-entropy loss for binary classification. (alias: SigmoidBCELoss)\n",
      "     |  \n",
      "     |  BCE loss is useful when training logistic regression. If `from_sigmoid`\n",
      "     |  is False (default), this loss computes:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      prob = \\frac{1}{1 + \\exp(-{pred})}\n",
      "     |  \n",
      "     |      L = - \\sum_i {label}_i * \\log({prob}_i) +\n",
      "     |          (1 - {label}_i) * \\log(1 - {prob}_i)\n",
      "     |  \n",
      "     |  If `from_sigmoid` is True, this loss computes:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      L = - \\sum_i {label}_i * \\log({pred}_i) +\n",
      "     |          (1 - {label}_i) * \\log(1 - {pred}_i)\n",
      "     |  \n",
      "     |  \n",
      "     |  `pred` and `label` can have arbitrary shape as long as they have the same\n",
      "     |  number of elements.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  from_sigmoid : bool, default is `False`\n",
      "     |      Whether the input is from the output of sigmoid. Set this to false will make\n",
      "     |      the loss calculate sigmoid and BCE together, which is more numerically\n",
      "     |      stable through log-sum-exp trick.\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**: prediction tensor with arbitrary shape\n",
      "     |      - **label**: target tensor with values in range `[0, 1]`. Must have the\n",
      "     |        same size as `pred`.\n",
      "     |      - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
      "     |        to the same shape as pred. For example, if pred has shape (64, 10)\n",
      "     |        and you want to weigh each sample in the batch separately,\n",
      "     |        sample_weight should have shape (64, 1).\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: loss tensor with shape (batch_size,). Dimenions other than\n",
      "     |        batch_axis are averaged out.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SigmoidBinaryCrossEntropyLoss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, from_sigmoid=False, weight=None, batch_axis=0, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, label, sample_weight=None)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    class SigmoidBinaryCrossEntropyLoss(Loss)\n",
      "     |  The cross-entropy loss for binary classification. (alias: SigmoidBCELoss)\n",
      "     |  \n",
      "     |  BCE loss is useful when training logistic regression. If `from_sigmoid`\n",
      "     |  is False (default), this loss computes:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      prob = \\frac{1}{1 + \\exp(-{pred})}\n",
      "     |  \n",
      "     |      L = - \\sum_i {label}_i * \\log({prob}_i) +\n",
      "     |          (1 - {label}_i) * \\log(1 - {prob}_i)\n",
      "     |  \n",
      "     |  If `from_sigmoid` is True, this loss computes:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      L = - \\sum_i {label}_i * \\log({pred}_i) +\n",
      "     |          (1 - {label}_i) * \\log(1 - {pred}_i)\n",
      "     |  \n",
      "     |  \n",
      "     |  `pred` and `label` can have arbitrary shape as long as they have the same\n",
      "     |  number of elements.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  from_sigmoid : bool, default is `False`\n",
      "     |      Whether the input is from the output of sigmoid. Set this to false will make\n",
      "     |      the loss calculate sigmoid and BCE together, which is more numerically\n",
      "     |      stable through log-sum-exp trick.\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**: prediction tensor with arbitrary shape\n",
      "     |      - **label**: target tensor with values in range `[0, 1]`. Must have the\n",
      "     |        same size as `pred`.\n",
      "     |      - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
      "     |        to the same shape as pred. For example, if pred has shape (64, 10)\n",
      "     |        and you want to weigh each sample in the batch separately,\n",
      "     |        sample_weight should have shape (64, 1).\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: loss tensor with shape (batch_size,). Dimenions other than\n",
      "     |        batch_axis are averaged out.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SigmoidBinaryCrossEntropyLoss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, from_sigmoid=False, weight=None, batch_axis=0, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, label, sample_weight=None)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    SoftmaxCELoss = class SoftmaxCrossEntropyLoss(Loss)\n",
      "     |  Computes the softmax cross entropy loss. (alias: SoftmaxCELoss)\n",
      "     |  \n",
      "     |  If `sparse_label` is `True` (default), label should contain integer\n",
      "     |  category indicators:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      \\DeclareMathOperator{softmax}{softmax}\n",
      "     |  \n",
      "     |      p = \\softmax({pred})\n",
      "     |  \n",
      "     |      L = -\\sum_i \\log p_{i,{label}_i}\n",
      "     |  \n",
      "     |  `label`'s shape should be `pred`'s shape with the `axis` dimension removed.\n",
      "     |  i.e. for `pred` with shape (1,2,3,4) and `axis = 2`, `label`'s shape should\n",
      "     |  be (1,2,4).\n",
      "     |  \n",
      "     |  If `sparse_label` is `False`, `label` should contain probability distribution\n",
      "     |  and `label`'s shape should be the same with `pred`:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      p = \\softmax({pred})\n",
      "     |  \n",
      "     |      L = -\\sum_i \\sum_j {label}_j \\log p_{ij}\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  axis : int, default -1\n",
      "     |      The axis to sum over when computing softmax and entropy.\n",
      "     |  sparse_label : bool, default True\n",
      "     |      Whether label is an integer array instead of probability distribution.\n",
      "     |  from_logits : bool, default False\n",
      "     |      Whether input is a log probability (usually from log_softmax) instead\n",
      "     |      of unnormalized numbers.\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**: the prediction tensor, where the `batch_axis` dimension\n",
      "     |        ranges over batch size and `axis` dimension ranges over the number\n",
      "     |        of classes.\n",
      "     |      - **label**: the truth tensor. When `sparse_label` is True, `label`'s\n",
      "     |        shape should be `pred`'s shape with the `axis` dimension removed.\n",
      "     |        i.e. for `pred` with shape (1,2,3,4) and `axis = 2`, `label`'s shape\n",
      "     |        should be (1,2,4) and values should be integers between 0 and 2. If\n",
      "     |        `sparse_label` is False, `label`'s shape must be the same as `pred`\n",
      "     |        and values should be floats in the range `[0, 1]`.\n",
      "     |      - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
      "     |        to the same shape as label. For example, if label has shape (64, 10)\n",
      "     |        and you want to weigh each sample in the batch separately,\n",
      "     |        sample_weight should have shape (64, 1).\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: loss tensor with shape (batch_size,). Dimenions other than\n",
      "     |        batch_axis are averaged out.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SoftmaxCrossEntropyLoss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, axis=-1, sparse_label=True, from_logits=False, weight=None, batch_axis=0, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, label, sample_weight=None)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    class SoftmaxCrossEntropyLoss(Loss)\n",
      "     |  Computes the softmax cross entropy loss. (alias: SoftmaxCELoss)\n",
      "     |  \n",
      "     |  If `sparse_label` is `True` (default), label should contain integer\n",
      "     |  category indicators:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      \\DeclareMathOperator{softmax}{softmax}\n",
      "     |  \n",
      "     |      p = \\softmax({pred})\n",
      "     |  \n",
      "     |      L = -\\sum_i \\log p_{i,{label}_i}\n",
      "     |  \n",
      "     |  `label`'s shape should be `pred`'s shape with the `axis` dimension removed.\n",
      "     |  i.e. for `pred` with shape (1,2,3,4) and `axis = 2`, `label`'s shape should\n",
      "     |  be (1,2,4).\n",
      "     |  \n",
      "     |  If `sparse_label` is `False`, `label` should contain probability distribution\n",
      "     |  and `label`'s shape should be the same with `pred`:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |  \n",
      "     |      p = \\softmax({pred})\n",
      "     |  \n",
      "     |      L = -\\sum_i \\sum_j {label}_j \\log p_{ij}\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  axis : int, default -1\n",
      "     |      The axis to sum over when computing softmax and entropy.\n",
      "     |  sparse_label : bool, default True\n",
      "     |      Whether label is an integer array instead of probability distribution.\n",
      "     |  from_logits : bool, default False\n",
      "     |      Whether input is a log probability (usually from log_softmax) instead\n",
      "     |      of unnormalized numbers.\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**: the prediction tensor, where the `batch_axis` dimension\n",
      "     |        ranges over batch size and `axis` dimension ranges over the number\n",
      "     |        of classes.\n",
      "     |      - **label**: the truth tensor. When `sparse_label` is True, `label`'s\n",
      "     |        shape should be `pred`'s shape with the `axis` dimension removed.\n",
      "     |        i.e. for `pred` with shape (1,2,3,4) and `axis = 2`, `label`'s shape\n",
      "     |        should be (1,2,4) and values should be integers between 0 and 2. If\n",
      "     |        `sparse_label` is False, `label`'s shape must be the same as `pred`\n",
      "     |        and values should be floats in the range `[0, 1]`.\n",
      "     |      - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
      "     |        to the same shape as label. For example, if label has shape (64, 10)\n",
      "     |        and you want to weigh each sample in the batch separately,\n",
      "     |        sample_weight should have shape (64, 1).\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: loss tensor with shape (batch_size,). Dimenions other than\n",
      "     |        batch_axis are averaged out.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SoftmaxCrossEntropyLoss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, axis=-1, sparse_label=True, from_logits=False, weight=None, batch_axis=0, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, label, sample_weight=None)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    class SquaredHingeLoss(Loss)\n",
      "     |  Calculates the soft-margin loss function used in SVMs:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |      L = \\sum_i max(0, {margin} - {pred}_i \\cdot {label}_i)^2\n",
      "     |  \n",
      "     |  where `pred` is the classifier prediction and `label` is the target tensor\n",
      "     |  containing values -1 or 1. `pred` and `label` can have arbitrary shape as\n",
      "     |  long as they have the same number of elements.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  margin : float\n",
      "     |      The margin in hinge loss. Defaults to 1.0\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**: prediction tensor with arbitrary shape\n",
      "     |      - **label**: truth tensor with values -1 or 1. Must have the same size\n",
      "     |        as pred.\n",
      "     |      - **sample_weight**: element-wise weighting tensor. Must be broadcastable\n",
      "     |        to the same shape as pred. For example, if pred has shape (64, 10)\n",
      "     |        and you want to weigh each sample in the batch separately,\n",
      "     |        sample_weight should have shape (64, 1).\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: loss tensor with shape (batch_size,). Dimenions other than\n",
      "     |        batch_axis are averaged out.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SquaredHingeLoss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, margin=1, weight=None, batch_axis=0, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, label, sample_weight=None)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "    \n",
      "    class TripletLoss(Loss)\n",
      "     |  Calculates triplet loss given three input tensors and a positive margin.\n",
      "     |  Triplet loss measures the relative similarity between prediction, a positive\n",
      "     |  example and a negative example:\n",
      "     |  \n",
      "     |  .. math::\n",
      "     |      L = \\sum_i \\max(\\Vert {pred}_i - {pos_i} \\Vert_2^2 -\n",
      "     |                      \\Vert {pred}_i - {neg_i} \\Vert_2^2 + {margin}, 0)\n",
      "     |  \n",
      "     |  `pred`, `positive` and `negative` can have arbitrary shape as long as they\n",
      "     |  have the same number of elements.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  margin : float\n",
      "     |      Margin of separation between correct and incorrect pair.\n",
      "     |  weight : float or None\n",
      "     |      Global scalar weight for loss.\n",
      "     |  batch_axis : int, default 0\n",
      "     |      The axis that represents mini-batch.\n",
      "     |  \n",
      "     |  \n",
      "     |  Inputs:\n",
      "     |      - **pred**: prediction tensor with arbitrary shape\n",
      "     |      - **positive**: positive example tensor with arbitrary shape. Must have\n",
      "     |        the same size as pred.\n",
      "     |      - **negative**: negative example tensor with arbitrary shape Must have\n",
      "     |        the same size as pred.\n",
      "     |  \n",
      "     |  Outputs:\n",
      "     |      - **loss**: loss tensor with shape (batch_size,).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TripletLoss\n",
      "     |      Loss\n",
      "     |      mxnet.gluon.block.HybridBlock\n",
      "     |      mxnet.gluon.block.Block\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, margin=1, weight=None, batch_axis=0, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  hybrid_forward(self, F, pred, positive, negative)\n",
      "     |      Overrides to construct symbolic graph for this `Block`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : Symbol or NDArray\n",
      "     |          The first input tensor.\n",
      "     |      *args : list of Symbol or list of NDArray\n",
      "     |          Additional input tensors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Loss:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.HybridBlock:\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Registers parameters.\n",
      "     |  \n",
      "     |  cast(self, dtype)\n",
      "     |      Cast this Block to use another data type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtype : str or numpy.dtype\n",
      "     |          The new data type.\n",
      "     |  \n",
      "     |  export(self, path, epoch=0)\n",
      "     |      Export HybridBlock to json format that can be loaded by\n",
      "     |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n",
      "     |      \n",
      "     |      .. note:: When there are only one input, it will have name `data`. When there\n",
      "     |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n",
      "     |          will be created, where xxxx is the 4 digits epoch number.\n",
      "     |      epoch : int\n",
      "     |          Epoch number of saved model.\n",
      "     |  \n",
      "     |  forward(self, x, *args)\n",
      "     |      Defines the forward computation. Arguments can be either\n",
      "     |      :py:class:`NDArray` or :py:class:`Symbol`.\n",
      "     |  \n",
      "     |  hybridize(self, active=True, **kwargs)\n",
      "     |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n",
      "     |      non-hybrid children.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      active : bool, default True\n",
      "     |          Whether to turn hybrid on or off.\n",
      "     |      static_alloc : bool, default False\n",
      "     |          Statically allocate memory to improve speed. Memory usage may increase.\n",
      "     |      static_shape : bool, default False\n",
      "     |          Optimize for invariant input shapes between iterations. Must also\n",
      "     |          set static_alloc to True. Change of input shapes is still allowed\n",
      "     |          but slower.\n",
      "     |  \n",
      "     |  infer_shape(self, *args)\n",
      "     |      Infers shape of Parameters from inputs.\n",
      "     |  \n",
      "     |  infer_type(self, *args)\n",
      "     |      Infers data type of Parameters from inputs.\n",
      "     |  \n",
      "     |  register_child(self, block, name=None)\n",
      "     |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      "     |      attributes will be registered automatically.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __call__(self, *args)\n",
      "     |      Calls forward. Only accepts positional arguments.\n",
      "     |  \n",
      "     |  apply(self, fn)\n",
      "     |      Applies ``fn`` recursively to every child block as well as self.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          Function to be applied to each submodule, of form `fn(block)`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      this block\n",
      "     |  \n",
      "     |  collect_params(self, select=None)\n",
      "     |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      "     |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      "     |      which match some given regular expressions.\n",
      "     |      \n",
      "     |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      "     |      'fc_bias']::\n",
      "     |      \n",
      "     |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      "     |      \n",
      "     |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      "     |      using regular expressions::\n",
      "     |      \n",
      "     |          model.collect_params('.*weight|.*bias')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      select : str\n",
      "     |          regular expressions\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      The selected :py:class:`ParameterDict`\n",
      "     |  \n",
      "     |  initialize(self, init=<mxnet.initializer.Uniform object at 0x000001B0DDE63CF8>, ctx=None, verbose=False, force_reinit=False)\n",
      "     |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      "     |      Equivalent to ``block.collect_params().initialize(...)``\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init : Initializer\n",
      "     |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      "     |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      "     |      ctx : Context or list of Context\n",
      "     |          Keeps a copy of Parameters on one or many context(s).\n",
      "     |      verbose : bool, default False\n",
      "     |          Whether to verbosely print out details on initialization.\n",
      "     |      force_reinit : bool, default False\n",
      "     |          Whether to force re-initialization if parameter is already initialized.\n",
      "     |  \n",
      "     |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      Load parameters from file previously saved by `save_parameters`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      "     |      [Deprecated] Please use load_parameters.\n",
      "     |      \n",
      "     |      Load parameters from file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to parameter file.\n",
      "     |      ctx : Context or list of Context, default cpu()\n",
      "     |          Context(s) to initialize loaded parameters on.\n",
      "     |      allow_missing : bool, default False\n",
      "     |          Whether to silently skip loading parameters not represents in the file.\n",
      "     |      ignore_extra : bool, default False\n",
      "     |          Whether to silently ignore parameters from the file that are not\n",
      "     |          present in this Block.\n",
      "     |  \n",
      "     |  name_scope(self)\n",
      "     |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      "     |      names. Should be used within a ``with`` statement::\n",
      "     |      \n",
      "     |          with self.name_scope():\n",
      "     |              self.dense = nn.Dense(20)\n",
      "     |      \n",
      "     |      Please refer to\n",
      "     |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n",
      "     |      for more info on prefix and naming.\n",
      "     |  \n",
      "     |  register_forward_hook(self, hook)\n",
      "     |      Registers a forward hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately after :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  register_forward_pre_hook(self, hook)\n",
      "     |      Registers a forward pre-hook on the block.\n",
      "     |      \n",
      "     |      The hook function is called immediately before :func:`forward`.\n",
      "     |      It should not modify the input or output.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      hook : callable\n",
      "     |          The forward hook function of form `hook(block, input) -> None`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      :class:`mxnet.gluon.utils.HookHandle`\n",
      "     |  \n",
      "     |  save_parameters(self, filename)\n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      "     |      method only saves parameters, not model structure. If you want to save\n",
      "     |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n",
      "     |  \n",
      "     |  save_params(self, filename)\n",
      "     |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      "     |      from SymbolBlock later, please use export instead.\n",
      "     |      \n",
      "     |      Save parameters to file.\n",
      "     |      \n",
      "     |      filename : str\n",
      "     |          Path to file.\n",
      "     |  \n",
      "     |  summary(self, *inputs)\n",
      "     |      Print the summary of the model's output and parameters.\n",
      "     |      \n",
      "     |      The network must have been initialized, and must not have been hybridized.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      inputs : object\n",
      "     |          Any input that the model supports. For any tensor in the input, only\n",
      "     |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "     |      Name of this :py:class:`Block`, without '_' in the end.\n",
      "     |  \n",
      "     |  params\n",
      "     |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      "     |      children's parameters).\n",
      "     |  \n",
      "     |  prefix\n",
      "     |      Prefix of this :py:class:`Block`.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Loss', 'L2Loss', 'L1Loss', 'SigmoidBinaryCrossEntropyLoss'...\n",
      "\n",
      "FILE\n",
      "    e:\\devtools\\anaconda3\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\loss.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gluon.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module mxnet.initializer in mxnet:\n",
      "\n",
      "NAME\n",
      "    mxnet.initializer - Weight initializer.\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        Initializer\n",
      "            Bilinear\n",
      "            Constant\n",
      "            FusedRNN\n",
      "            LSTMBias\n",
      "            Normal\n",
      "            One\n",
      "            Orthogonal\n",
      "            Uniform\n",
      "            Xavier\n",
      "                MSRAPrelu\n",
      "            Zero\n",
      "        Load\n",
      "        Mixed\n",
      "    builtins.str(builtins.object)\n",
      "        InitDesc\n",
      "    \n",
      "    class Bilinear(Initializer)\n",
      "     |  Initialize weight for upsampling layers.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Bilinear\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Initializer:\n",
      "     |  \n",
      "     |  __call__(self, desc, arr)\n",
      "     |      Initialize an array\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      desc : InitDesc\n",
      "     |          Initialization pattern descriptor.\n",
      "     |      \n",
      "     |      arr : NDArray\n",
      "     |          The array to be initialized.\n",
      "     |  \n",
      "     |  dumps(self)\n",
      "     |      Saves the initializer to string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          JSON formatted string that describes the initializer.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> # Create initializer and retrieve its parameters\n",
      "     |      ...\n",
      "     |      >>> init = mx.init.Normal(0.5)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      "     |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      "     |  \n",
      "     |  set_verbosity(self, verbose=False, print_func=None)\n",
      "     |      Switch on/off verbose mode\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : bool\n",
      "     |          switch on/off verbose mode\n",
      "     |      print_func : function\n",
      "     |          A function that computes statistics of initialized arrays.\n",
      "     |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      "     |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Constant(Initializer)\n",
      "     |  Initializes the weights to a given value.\n",
      "     |  The value passed in can be a scalar or a NDarray that matches the shape\n",
      "     |  of the parameter to be set.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  value : float, NDArray\n",
      "     |      Value to set.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Constant\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, value)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Initializer:\n",
      "     |  \n",
      "     |  __call__(self, desc, arr)\n",
      "     |      Initialize an array\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      desc : InitDesc\n",
      "     |          Initialization pattern descriptor.\n",
      "     |      \n",
      "     |      arr : NDArray\n",
      "     |          The array to be initialized.\n",
      "     |  \n",
      "     |  dumps(self)\n",
      "     |      Saves the initializer to string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          JSON formatted string that describes the initializer.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> # Create initializer and retrieve its parameters\n",
      "     |      ...\n",
      "     |      >>> init = mx.init.Normal(0.5)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      "     |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      "     |  \n",
      "     |  set_verbosity(self, verbose=False, print_func=None)\n",
      "     |      Switch on/off verbose mode\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : bool\n",
      "     |          switch on/off verbose mode\n",
      "     |      print_func : function\n",
      "     |          A function that computes statistics of initialized arrays.\n",
      "     |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      "     |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class FusedRNN(Initializer)\n",
      "     |  Initialize parameters for fused rnn layers.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  init : Initializer\n",
      "     |      initializer applied to unpacked weights. Fall back to global\n",
      "     |      initializer if None.\n",
      "     |  num_hidden : int\n",
      "     |      should be the same with arguments passed to FusedRNNCell.\n",
      "     |  num_layers : int\n",
      "     |      should be the same with arguments passed to FusedRNNCell.\n",
      "     |  mode : str\n",
      "     |      should be the same with arguments passed to FusedRNNCell.\n",
      "     |  bidirectional : bool\n",
      "     |      should be the same with arguments passed to FusedRNNCell.\n",
      "     |  forget_bias : float\n",
      "     |      should be the same with arguments passed to FusedRNNCell.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FusedRNN\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, init, num_hidden, num_layers, mode, bidirectional=False, forget_bias=1.0)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Initializer:\n",
      "     |  \n",
      "     |  __call__(self, desc, arr)\n",
      "     |      Initialize an array\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      desc : InitDesc\n",
      "     |          Initialization pattern descriptor.\n",
      "     |      \n",
      "     |      arr : NDArray\n",
      "     |          The array to be initialized.\n",
      "     |  \n",
      "     |  dumps(self)\n",
      "     |      Saves the initializer to string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          JSON formatted string that describes the initializer.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> # Create initializer and retrieve its parameters\n",
      "     |      ...\n",
      "     |      >>> init = mx.init.Normal(0.5)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      "     |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      "     |  \n",
      "     |  set_verbosity(self, verbose=False, print_func=None)\n",
      "     |      Switch on/off verbose mode\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : bool\n",
      "     |          switch on/off verbose mode\n",
      "     |      print_func : function\n",
      "     |          A function that computes statistics of initialized arrays.\n",
      "     |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      "     |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class InitDesc(builtins.str)\n",
      "     |  Descriptor for the initialization pattern.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  name : str\n",
      "     |      Name of variable.\n",
      "     |  attrs : dict of str to str\n",
      "     |      Attributes of this variable taken from ``Symbol.attr_dict``.\n",
      "     |  global_init : Initializer\n",
      "     |      Global initializer to fallback to.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      InitDesc\n",
      "     |      builtins.str\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, name, attrs=None, global_init=None)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.str:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __format__(...)\n",
      "     |      S.__format__(format_spec) -> str\n",
      "     |      \n",
      "     |      Return a formatted version of S as described by format_spec.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __getnewargs__(...)\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mod__(self, value, /)\n",
      "     |      Return self%value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.n\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmod__(self, value, /)\n",
      "     |      Return value%self.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __sizeof__(...)\n",
      "     |      S.__sizeof__() -> size of S in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  capitalize(...)\n",
      "     |      S.capitalize() -> str\n",
      "     |      \n",
      "     |      Return a capitalized version of S, i.e. make the first character\n",
      "     |      have upper case and the rest lower case.\n",
      "     |  \n",
      "     |  casefold(...)\n",
      "     |      S.casefold() -> str\n",
      "     |      \n",
      "     |      Return a version of S suitable for caseless comparisons.\n",
      "     |  \n",
      "     |  center(...)\n",
      "     |      S.center(width[, fillchar]) -> str\n",
      "     |      \n",
      "     |      Return S centered in a string of length width. Padding is\n",
      "     |      done using the specified fill character (default is a space)\n",
      "     |  \n",
      "     |  count(...)\n",
      "     |      S.count(sub[, start[, end]]) -> int\n",
      "     |      \n",
      "     |      Return the number of non-overlapping occurrences of substring sub in\n",
      "     |      string S[start:end].  Optional arguments start and end are\n",
      "     |      interpreted as in slice notation.\n",
      "     |  \n",
      "     |  encode(...)\n",
      "     |      S.encode(encoding='utf-8', errors='strict') -> bytes\n",
      "     |      \n",
      "     |      Encode S using the codec registered for encoding. Default encoding\n",
      "     |      is 'utf-8'. errors may be given to set a different error\n",
      "     |      handling scheme. Default is 'strict' meaning that encoding errors raise\n",
      "     |      a UnicodeEncodeError. Other possible values are 'ignore', 'replace' and\n",
      "     |      'xmlcharrefreplace' as well as any other name registered with\n",
      "     |      codecs.register_error that can handle UnicodeEncodeErrors.\n",
      "     |  \n",
      "     |  endswith(...)\n",
      "     |      S.endswith(suffix[, start[, end]]) -> bool\n",
      "     |      \n",
      "     |      Return True if S ends with the specified suffix, False otherwise.\n",
      "     |      With optional start, test S beginning at that position.\n",
      "     |      With optional end, stop comparing S at that position.\n",
      "     |      suffix can also be a tuple of strings to try.\n",
      "     |  \n",
      "     |  expandtabs(...)\n",
      "     |      S.expandtabs(tabsize=8) -> str\n",
      "     |      \n",
      "     |      Return a copy of S where all tab characters are expanded using spaces.\n",
      "     |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
      "     |  \n",
      "     |  find(...)\n",
      "     |      S.find(sub[, start[, end]]) -> int\n",
      "     |      \n",
      "     |      Return the lowest index in S where substring sub is found,\n",
      "     |      such that sub is contained within S[start:end].  Optional\n",
      "     |      arguments start and end are interpreted as in slice notation.\n",
      "     |      \n",
      "     |      Return -1 on failure.\n",
      "     |  \n",
      "     |  format(...)\n",
      "     |      S.format(*args, **kwargs) -> str\n",
      "     |      \n",
      "     |      Return a formatted version of S, using substitutions from args and kwargs.\n",
      "     |      The substitutions are identified by braces ('{' and '}').\n",
      "     |  \n",
      "     |  format_map(...)\n",
      "     |      S.format_map(mapping) -> str\n",
      "     |      \n",
      "     |      Return a formatted version of S, using substitutions from mapping.\n",
      "     |      The substitutions are identified by braces ('{' and '}').\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      S.index(sub[, start[, end]]) -> int\n",
      "     |      \n",
      "     |      Return the lowest index in S where substring sub is found, \n",
      "     |      such that sub is contained within S[start:end].  Optional\n",
      "     |      arguments start and end are interpreted as in slice notation.\n",
      "     |      \n",
      "     |      Raises ValueError when the substring is not found.\n",
      "     |  \n",
      "     |  isalnum(...)\n",
      "     |      S.isalnum() -> bool\n",
      "     |      \n",
      "     |      Return True if all characters in S are alphanumeric\n",
      "     |      and there is at least one character in S, False otherwise.\n",
      "     |  \n",
      "     |  isalpha(...)\n",
      "     |      S.isalpha() -> bool\n",
      "     |      \n",
      "     |      Return True if all characters in S are alphabetic\n",
      "     |      and there is at least one character in S, False otherwise.\n",
      "     |  \n",
      "     |  isdecimal(...)\n",
      "     |      S.isdecimal() -> bool\n",
      "     |      \n",
      "     |      Return True if there are only decimal characters in S,\n",
      "     |      False otherwise.\n",
      "     |  \n",
      "     |  isdigit(...)\n",
      "     |      S.isdigit() -> bool\n",
      "     |      \n",
      "     |      Return True if all characters in S are digits\n",
      "     |      and there is at least one character in S, False otherwise.\n",
      "     |  \n",
      "     |  isidentifier(...)\n",
      "     |      S.isidentifier() -> bool\n",
      "     |      \n",
      "     |      Return True if S is a valid identifier according\n",
      "     |      to the language definition.\n",
      "     |      \n",
      "     |      Use keyword.iskeyword() to test for reserved identifiers\n",
      "     |      such as \"def\" and \"class\".\n",
      "     |  \n",
      "     |  islower(...)\n",
      "     |      S.islower() -> bool\n",
      "     |      \n",
      "     |      Return True if all cased characters in S are lowercase and there is\n",
      "     |      at least one cased character in S, False otherwise.\n",
      "     |  \n",
      "     |  isnumeric(...)\n",
      "     |      S.isnumeric() -> bool\n",
      "     |      \n",
      "     |      Return True if there are only numeric characters in S,\n",
      "     |      False otherwise.\n",
      "     |  \n",
      "     |  isprintable(...)\n",
      "     |      S.isprintable() -> bool\n",
      "     |      \n",
      "     |      Return True if all characters in S are considered\n",
      "     |      printable in repr() or S is empty, False otherwise.\n",
      "     |  \n",
      "     |  isspace(...)\n",
      "     |      S.isspace() -> bool\n",
      "     |      \n",
      "     |      Return True if all characters in S are whitespace\n",
      "     |      and there is at least one character in S, False otherwise.\n",
      "     |  \n",
      "     |  istitle(...)\n",
      "     |      S.istitle() -> bool\n",
      "     |      \n",
      "     |      Return True if S is a titlecased string and there is at least one\n",
      "     |      character in S, i.e. upper- and titlecase characters may only\n",
      "     |      follow uncased characters and lowercase characters only cased ones.\n",
      "     |      Return False otherwise.\n",
      "     |  \n",
      "     |  isupper(...)\n",
      "     |      S.isupper() -> bool\n",
      "     |      \n",
      "     |      Return True if all cased characters in S are uppercase and there is\n",
      "     |      at least one cased character in S, False otherwise.\n",
      "     |  \n",
      "     |  join(...)\n",
      "     |      S.join(iterable) -> str\n",
      "     |      \n",
      "     |      Return a string which is the concatenation of the strings in the\n",
      "     |      iterable.  The separator between elements is S.\n",
      "     |  \n",
      "     |  ljust(...)\n",
      "     |      S.ljust(width[, fillchar]) -> str\n",
      "     |      \n",
      "     |      Return S left-justified in a Unicode string of length width. Padding is\n",
      "     |      done using the specified fill character (default is a space).\n",
      "     |  \n",
      "     |  lower(...)\n",
      "     |      S.lower() -> str\n",
      "     |      \n",
      "     |      Return a copy of the string S converted to lowercase.\n",
      "     |  \n",
      "     |  lstrip(...)\n",
      "     |      S.lstrip([chars]) -> str\n",
      "     |      \n",
      "     |      Return a copy of the string S with leading whitespace removed.\n",
      "     |      If chars is given and not None, remove characters in chars instead.\n",
      "     |  \n",
      "     |  partition(...)\n",
      "     |      S.partition(sep) -> (head, sep, tail)\n",
      "     |      \n",
      "     |      Search for the separator sep in S, and return the part before it,\n",
      "     |      the separator itself, and the part after it.  If the separator is not\n",
      "     |      found, return S and two empty strings.\n",
      "     |  \n",
      "     |  replace(...)\n",
      "     |      S.replace(old, new[, count]) -> str\n",
      "     |      \n",
      "     |      Return a copy of S with all occurrences of substring\n",
      "     |      old replaced by new.  If the optional argument count is\n",
      "     |      given, only the first count occurrences are replaced.\n",
      "     |  \n",
      "     |  rfind(...)\n",
      "     |      S.rfind(sub[, start[, end]]) -> int\n",
      "     |      \n",
      "     |      Return the highest index in S where substring sub is found,\n",
      "     |      such that sub is contained within S[start:end].  Optional\n",
      "     |      arguments start and end are interpreted as in slice notation.\n",
      "     |      \n",
      "     |      Return -1 on failure.\n",
      "     |  \n",
      "     |  rindex(...)\n",
      "     |      S.rindex(sub[, start[, end]]) -> int\n",
      "     |      \n",
      "     |      Return the highest index in S where substring sub is found,\n",
      "     |      such that sub is contained within S[start:end].  Optional\n",
      "     |      arguments start and end are interpreted as in slice notation.\n",
      "     |      \n",
      "     |      Raises ValueError when the substring is not found.\n",
      "     |  \n",
      "     |  rjust(...)\n",
      "     |      S.rjust(width[, fillchar]) -> str\n",
      "     |      \n",
      "     |      Return S right-justified in a string of length width. Padding is\n",
      "     |      done using the specified fill character (default is a space).\n",
      "     |  \n",
      "     |  rpartition(...)\n",
      "     |      S.rpartition(sep) -> (head, sep, tail)\n",
      "     |      \n",
      "     |      Search for the separator sep in S, starting at the end of S, and return\n",
      "     |      the part before it, the separator itself, and the part after it.  If the\n",
      "     |      separator is not found, return two empty strings and S.\n",
      "     |  \n",
      "     |  rsplit(...)\n",
      "     |      S.rsplit(sep=None, maxsplit=-1) -> list of strings\n",
      "     |      \n",
      "     |      Return a list of the words in S, using sep as the\n",
      "     |      delimiter string, starting at the end of the string and\n",
      "     |      working to the front.  If maxsplit is given, at most maxsplit\n",
      "     |      splits are done. If sep is not specified, any whitespace string\n",
      "     |      is a separator.\n",
      "     |  \n",
      "     |  rstrip(...)\n",
      "     |      S.rstrip([chars]) -> str\n",
      "     |      \n",
      "     |      Return a copy of the string S with trailing whitespace removed.\n",
      "     |      If chars is given and not None, remove characters in chars instead.\n",
      "     |  \n",
      "     |  split(...)\n",
      "     |      S.split(sep=None, maxsplit=-1) -> list of strings\n",
      "     |      \n",
      "     |      Return a list of the words in S, using sep as the\n",
      "     |      delimiter string.  If maxsplit is given, at most maxsplit\n",
      "     |      splits are done. If sep is not specified or is None, any\n",
      "     |      whitespace string is a separator and empty strings are\n",
      "     |      removed from the result.\n",
      "     |  \n",
      "     |  splitlines(...)\n",
      "     |      S.splitlines([keepends]) -> list of strings\n",
      "     |      \n",
      "     |      Return a list of the lines in S, breaking at line boundaries.\n",
      "     |      Line breaks are not included in the resulting list unless keepends\n",
      "     |      is given and true.\n",
      "     |  \n",
      "     |  startswith(...)\n",
      "     |      S.startswith(prefix[, start[, end]]) -> bool\n",
      "     |      \n",
      "     |      Return True if S starts with the specified prefix, False otherwise.\n",
      "     |      With optional start, test S beginning at that position.\n",
      "     |      With optional end, stop comparing S at that position.\n",
      "     |      prefix can also be a tuple of strings to try.\n",
      "     |  \n",
      "     |  strip(...)\n",
      "     |      S.strip([chars]) -> str\n",
      "     |      \n",
      "     |      Return a copy of the string S with leading and trailing\n",
      "     |      whitespace removed.\n",
      "     |      If chars is given and not None, remove characters in chars instead.\n",
      "     |  \n",
      "     |  swapcase(...)\n",
      "     |      S.swapcase() -> str\n",
      "     |      \n",
      "     |      Return a copy of S with uppercase characters converted to lowercase\n",
      "     |      and vice versa.\n",
      "     |  \n",
      "     |  title(...)\n",
      "     |      S.title() -> str\n",
      "     |      \n",
      "     |      Return a titlecased version of S, i.e. words start with title case\n",
      "     |      characters, all remaining cased characters have lower case.\n",
      "     |  \n",
      "     |  translate(...)\n",
      "     |      S.translate(table) -> str\n",
      "     |      \n",
      "     |      Return a copy of the string S in which each character has been mapped\n",
      "     |      through the given translation table. The table must implement\n",
      "     |      lookup/indexing via __getitem__, for instance a dictionary or list,\n",
      "     |      mapping Unicode ordinals to Unicode ordinals, strings, or None. If\n",
      "     |      this operation raises LookupError, the character is left untouched.\n",
      "     |      Characters mapped to None are deleted.\n",
      "     |  \n",
      "     |  upper(...)\n",
      "     |      S.upper() -> str\n",
      "     |      \n",
      "     |      Return a copy of S converted to uppercase.\n",
      "     |  \n",
      "     |  zfill(...)\n",
      "     |      S.zfill(width) -> str\n",
      "     |      \n",
      "     |      Pad a numeric string S with zeros on the left, to fill a field\n",
      "     |      of the specified width. The string S is never truncated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.str:\n",
      "     |  \n",
      "     |  maketrans(x, y=None, z=None, /)\n",
      "     |      Return a translation table usable for str.translate().\n",
      "     |      \n",
      "     |      If there is only one argument, it must be a dictionary mapping Unicode\n",
      "     |      ordinals (integers) or characters to Unicode ordinals, strings or None.\n",
      "     |      Character keys will be then converted to ordinals.\n",
      "     |      If there are two arguments, they must be strings of equal length, and\n",
      "     |      in the resulting dictionary, each character in x will be mapped to the\n",
      "     |      character at the same position in y. If there is a third argument, it\n",
      "     |      must be a string, whose characters will be mapped to None in the result.\n",
      "    \n",
      "    class Initializer(builtins.object)\n",
      "     |  The base class of an initializer.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, desc, arr)\n",
      "     |      Initialize an array\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      desc : InitDesc\n",
      "     |          Initialization pattern descriptor.\n",
      "     |      \n",
      "     |      arr : NDArray\n",
      "     |          The array to be initialized.\n",
      "     |  \n",
      "     |  __init__(self, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  dumps(self)\n",
      "     |      Saves the initializer to string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          JSON formatted string that describes the initializer.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> # Create initializer and retrieve its parameters\n",
      "     |      ...\n",
      "     |      >>> init = mx.init.Normal(0.5)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      "     |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      "     |  \n",
      "     |  set_verbosity(self, verbose=False, print_func=None)\n",
      "     |      Switch on/off verbose mode\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : bool\n",
      "     |          switch on/off verbose mode\n",
      "     |      print_func : function\n",
      "     |          A function that computes statistics of initialized arrays.\n",
      "     |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      "     |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LSTMBias(Initializer)\n",
      "     |  Initialize all biases of an LSTMCell to 0.0 except for\n",
      "     |  the forget gate whose bias is set to custom value.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  forget_bias: float, default 1.0\n",
      "     |      bias for the forget gate. Jozefowicz et al. 2015 recommends\n",
      "     |      setting this to 1.0.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LSTMBias\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, forget_bias=1.0)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Initializer:\n",
      "     |  \n",
      "     |  __call__(self, desc, arr)\n",
      "     |      Initialize an array\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      desc : InitDesc\n",
      "     |          Initialization pattern descriptor.\n",
      "     |      \n",
      "     |      arr : NDArray\n",
      "     |          The array to be initialized.\n",
      "     |  \n",
      "     |  dumps(self)\n",
      "     |      Saves the initializer to string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          JSON formatted string that describes the initializer.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> # Create initializer and retrieve its parameters\n",
      "     |      ...\n",
      "     |      >>> init = mx.init.Normal(0.5)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      "     |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      "     |  \n",
      "     |  set_verbosity(self, verbose=False, print_func=None)\n",
      "     |      Switch on/off verbose mode\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : bool\n",
      "     |          switch on/off verbose mode\n",
      "     |      print_func : function\n",
      "     |          A function that computes statistics of initialized arrays.\n",
      "     |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      "     |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Load(builtins.object)\n",
      "     |  Initializes variables by loading data from file or dict.\n",
      "     |  \n",
      "     |  **Note** Load will drop ``arg:`` or ``aux:`` from name and\n",
      "     |  initialize the variables that match with the prefix dropped.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  param: str or dict of str->`NDArray`\n",
      "     |      Parameter file or dict mapping name to NDArray.\n",
      "     |  default_init: Initializer\n",
      "     |      Default initializer when name is not found in `param`.\n",
      "     |  verbose: bool\n",
      "     |      Flag for enabling logging of source when initializing.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, name, arr)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, param, default_init=None, verbose=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MSRAPrelu(Xavier)\n",
      "     |  Initialize the weight according to a MSRA paper.\n",
      "     |  \n",
      "     |  This initializer implements *Delving Deep into Rectifiers: Surpassing\n",
      "     |  Human-Level Performance on ImageNet Classification*, available at\n",
      "     |  https://arxiv.org/abs/1502.01852.\n",
      "     |  \n",
      "     |  This initializer is proposed for initialization related to ReLu activation,\n",
      "     |  it maked some changes on top of Xavier method.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  factor_type: str, optional\n",
      "     |      Can be ``'avg'``, ``'in'``, or ``'out'``.\n",
      "     |  \n",
      "     |  slope: float, optional\n",
      "     |      initial slope of any PReLU (or similar) nonlinearities.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MSRAPrelu\n",
      "     |      Xavier\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, factor_type='avg', slope=0.25)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Initializer:\n",
      "     |  \n",
      "     |  __call__(self, desc, arr)\n",
      "     |      Initialize an array\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      desc : InitDesc\n",
      "     |          Initialization pattern descriptor.\n",
      "     |      \n",
      "     |      arr : NDArray\n",
      "     |          The array to be initialized.\n",
      "     |  \n",
      "     |  dumps(self)\n",
      "     |      Saves the initializer to string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          JSON formatted string that describes the initializer.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> # Create initializer and retrieve its parameters\n",
      "     |      ...\n",
      "     |      >>> init = mx.init.Normal(0.5)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      "     |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      "     |  \n",
      "     |  set_verbosity(self, verbose=False, print_func=None)\n",
      "     |      Switch on/off verbose mode\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : bool\n",
      "     |          switch on/off verbose mode\n",
      "     |      print_func : function\n",
      "     |          A function that computes statistics of initialized arrays.\n",
      "     |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      "     |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Mixed(builtins.object)\n",
      "     |  Initialize parameters using multiple initializers.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  patterns: list of str\n",
      "     |      List of regular expressions matching parameter names.\n",
      "     |  initializers: list of Initializer\n",
      "     |      List of initializers corresponding to `patterns`.\n",
      "     |  \n",
      "     |  Example\n",
      "     |  -------\n",
      "     |  >>> # Given 'module', an instance of 'mxnet.module.Module', initialize biases to zero\n",
      "     |  ... # and every other parameter to random values with uniform distribution.\n",
      "     |  ...\n",
      "     |  >>> init = mx.initializer.Mixed(['bias', '.*'], [mx.init.Zero(), mx.init.Uniform(0.1)])\n",
      "     |  >>> module.init_params(init)\n",
      "     |  >>>\n",
      "     |  >>> for dictionary in module.get_params():\n",
      "     |  ...     for key in dictionary:\n",
      "     |  ...         print(key)\n",
      "     |  ...         print(dictionary[key].asnumpy())\n",
      "     |  ...\n",
      "     |  fullyconnected1_weight\n",
      "     |  [[ 0.0097627   0.01856892  0.04303787]]\n",
      "     |  fullyconnected1_bias\n",
      "     |  [ 0.]\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, name, arr)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, patterns, initializers)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Normal(Initializer)\n",
      "     |  Initializes weights with random values sampled from a normal distribution\n",
      "     |  with a mean of zero and standard deviation of `sigma`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  sigma : float, optional\n",
      "     |      Standard deviation of the normal distribution.\n",
      "     |      Default standard deviation is 0.01.\n",
      "     |  \n",
      "     |  Example\n",
      "     |  -------\n",
      "     |  >>> # Given 'module', an instance of 'mxnet.module.Module', initialize weights\n",
      "     |  >>> # to random values sampled from a normal distribution.\n",
      "     |  ...\n",
      "     |  >>> init = mx.init.Normal(0.5)\n",
      "     |  >>> module.init_params(init)\n",
      "     |  >>> for dictionary in module.get_params():\n",
      "     |  ...     for key in dictionary:\n",
      "     |  ...         print(key)\n",
      "     |  ...         print(dictionary[key].asnumpy())\n",
      "     |  ...\n",
      "     |  fullyconnected0_weight\n",
      "     |  [[-0.3214761  -0.12660924  0.53789419]]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Normal\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, sigma=0.01)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Initializer:\n",
      "     |  \n",
      "     |  __call__(self, desc, arr)\n",
      "     |      Initialize an array\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      desc : InitDesc\n",
      "     |          Initialization pattern descriptor.\n",
      "     |      \n",
      "     |      arr : NDArray\n",
      "     |          The array to be initialized.\n",
      "     |  \n",
      "     |  dumps(self)\n",
      "     |      Saves the initializer to string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          JSON formatted string that describes the initializer.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> # Create initializer and retrieve its parameters\n",
      "     |      ...\n",
      "     |      >>> init = mx.init.Normal(0.5)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      "     |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      "     |  \n",
      "     |  set_verbosity(self, verbose=False, print_func=None)\n",
      "     |      Switch on/off verbose mode\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : bool\n",
      "     |          switch on/off verbose mode\n",
      "     |      print_func : function\n",
      "     |          A function that computes statistics of initialized arrays.\n",
      "     |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      "     |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class One(Initializer)\n",
      "     |  Initializes weights to one.\n",
      "     |  \n",
      "     |  Example\n",
      "     |  -------\n",
      "     |  >>> # Given 'module', an instance of 'mxnet.module.Module', initialize weights to one.\n",
      "     |  ...\n",
      "     |  >>> init = mx.initializer.One()\n",
      "     |  >>> module.init_params(init)\n",
      "     |  >>> for dictionary in module.get_params():\n",
      "     |  ...     for key in dictionary:\n",
      "     |  ...         print(key)\n",
      "     |  ...         print(dictionary[key].asnumpy())\n",
      "     |  ...\n",
      "     |  fullyconnected0_weight\n",
      "     |  [[ 1.  1.  1.]]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      One\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Initializer:\n",
      "     |  \n",
      "     |  __call__(self, desc, arr)\n",
      "     |      Initialize an array\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      desc : InitDesc\n",
      "     |          Initialization pattern descriptor.\n",
      "     |      \n",
      "     |      arr : NDArray\n",
      "     |          The array to be initialized.\n",
      "     |  \n",
      "     |  dumps(self)\n",
      "     |      Saves the initializer to string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          JSON formatted string that describes the initializer.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> # Create initializer and retrieve its parameters\n",
      "     |      ...\n",
      "     |      >>> init = mx.init.Normal(0.5)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      "     |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      "     |  \n",
      "     |  set_verbosity(self, verbose=False, print_func=None)\n",
      "     |      Switch on/off verbose mode\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : bool\n",
      "     |          switch on/off verbose mode\n",
      "     |      print_func : function\n",
      "     |          A function that computes statistics of initialized arrays.\n",
      "     |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      "     |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Orthogonal(Initializer)\n",
      "     |  Initialize weight as orthogonal matrix.\n",
      "     |  \n",
      "     |  This initializer implements *Exact solutions to the nonlinear dynamics of\n",
      "     |  learning in deep linear neural networks*, available at\n",
      "     |  https://arxiv.org/abs/1312.6120.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  scale : float optional\n",
      "     |      Scaling factor of weight.\n",
      "     |  \n",
      "     |  rand_type: string optional\n",
      "     |      Use \"uniform\" or \"normal\" random number to initialize weight.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Orthogonal\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, scale=1.414, rand_type='uniform')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Initializer:\n",
      "     |  \n",
      "     |  __call__(self, desc, arr)\n",
      "     |      Initialize an array\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      desc : InitDesc\n",
      "     |          Initialization pattern descriptor.\n",
      "     |      \n",
      "     |      arr : NDArray\n",
      "     |          The array to be initialized.\n",
      "     |  \n",
      "     |  dumps(self)\n",
      "     |      Saves the initializer to string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          JSON formatted string that describes the initializer.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> # Create initializer and retrieve its parameters\n",
      "     |      ...\n",
      "     |      >>> init = mx.init.Normal(0.5)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      "     |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      "     |  \n",
      "     |  set_verbosity(self, verbose=False, print_func=None)\n",
      "     |      Switch on/off verbose mode\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : bool\n",
      "     |          switch on/off verbose mode\n",
      "     |      print_func : function\n",
      "     |          A function that computes statistics of initialized arrays.\n",
      "     |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      "     |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Uniform(Initializer)\n",
      "     |  Initializes weights with random values uniformly sampled from a given range.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  scale : float, optional\n",
      "     |      The bound on the range of the generated random values.\n",
      "     |      Values are generated from the range [-`scale`, `scale`].\n",
      "     |      Default scale is 0.07.\n",
      "     |  \n",
      "     |  Example\n",
      "     |  -------\n",
      "     |  >>> # Given 'module', an instance of 'mxnet.module.Module', initialize weights\n",
      "     |  >>> # to random values uniformly sampled between -0.1 and 0.1.\n",
      "     |  ...\n",
      "     |  >>> init = mx.init.Uniform(0.1)\n",
      "     |  >>> module.init_params(init)\n",
      "     |  >>> for dictionary in module.get_params():\n",
      "     |  ...     for key in dictionary:\n",
      "     |  ...         print(key)\n",
      "     |  ...         print(dictionary[key].asnumpy())\n",
      "     |  ...\n",
      "     |  fullyconnected0_weight\n",
      "     |  [[ 0.01360891 -0.02144304  0.08511933]]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Uniform\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, scale=0.07)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Initializer:\n",
      "     |  \n",
      "     |  __call__(self, desc, arr)\n",
      "     |      Initialize an array\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      desc : InitDesc\n",
      "     |          Initialization pattern descriptor.\n",
      "     |      \n",
      "     |      arr : NDArray\n",
      "     |          The array to be initialized.\n",
      "     |  \n",
      "     |  dumps(self)\n",
      "     |      Saves the initializer to string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          JSON formatted string that describes the initializer.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> # Create initializer and retrieve its parameters\n",
      "     |      ...\n",
      "     |      >>> init = mx.init.Normal(0.5)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      "     |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      "     |  \n",
      "     |  set_verbosity(self, verbose=False, print_func=None)\n",
      "     |      Switch on/off verbose mode\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : bool\n",
      "     |          switch on/off verbose mode\n",
      "     |      print_func : function\n",
      "     |          A function that computes statistics of initialized arrays.\n",
      "     |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      "     |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Xavier(Initializer)\n",
      "     |  Returns an initializer performing \"Xavier\" initialization for weights.\n",
      "     |  \n",
      "     |  This initializer is designed to keep the scale of gradients roughly the same\n",
      "     |  in all layers.\n",
      "     |  \n",
      "     |  By default, `rnd_type` is ``'uniform'`` and `factor_type` is ``'avg'``,\n",
      "     |  the initializer fills the weights with random numbers in the range\n",
      "     |  of :math:`[-c, c]`, where :math:`c = \\sqrt{\\frac{3.}{0.5 * (n_{in} + n_{out})}}`.\n",
      "     |  :math:`n_{in}` is the number of neurons feeding into weights, and :math:`n_{out}` is\n",
      "     |  the number of neurons the result is fed to.\n",
      "     |  \n",
      "     |  If `rnd_type` is ``'uniform'`` and `factor_type` is ``'in'``,\n",
      "     |  the :math:`c = \\sqrt{\\frac{3.}{n_{in}}}`.\n",
      "     |  Similarly when `factor_type` is ``'out'``, the :math:`c = \\sqrt{\\frac{3.}{n_{out}}}`.\n",
      "     |  \n",
      "     |  If `rnd_type` is ``'gaussian'`` and `factor_type` is ``'avg'``,\n",
      "     |  the initializer fills the weights with numbers from normal distribution with\n",
      "     |  a standard deviation of :math:`\\sqrt{\\frac{3.}{0.5 * (n_{in} + n_{out})}}`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  rnd_type: str, optional\n",
      "     |      Random generator type, can be ``'gaussian'`` or ``'uniform'``.\n",
      "     |  \n",
      "     |  factor_type: str, optional\n",
      "     |      Can be ``'avg'``, ``'in'``, or ``'out'``.\n",
      "     |  \n",
      "     |  magnitude: float, optional\n",
      "     |      Scale of random number.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Xavier\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, rnd_type='uniform', factor_type='avg', magnitude=3)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Initializer:\n",
      "     |  \n",
      "     |  __call__(self, desc, arr)\n",
      "     |      Initialize an array\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      desc : InitDesc\n",
      "     |          Initialization pattern descriptor.\n",
      "     |      \n",
      "     |      arr : NDArray\n",
      "     |          The array to be initialized.\n",
      "     |  \n",
      "     |  dumps(self)\n",
      "     |      Saves the initializer to string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          JSON formatted string that describes the initializer.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> # Create initializer and retrieve its parameters\n",
      "     |      ...\n",
      "     |      >>> init = mx.init.Normal(0.5)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      "     |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      "     |  \n",
      "     |  set_verbosity(self, verbose=False, print_func=None)\n",
      "     |      Switch on/off verbose mode\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : bool\n",
      "     |          switch on/off verbose mode\n",
      "     |      print_func : function\n",
      "     |          A function that computes statistics of initialized arrays.\n",
      "     |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      "     |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Zero(Initializer)\n",
      "     |  Initializes weights to zero.\n",
      "     |  \n",
      "     |  Example\n",
      "     |  -------\n",
      "     |  >>> # Given 'module', an instance of 'mxnet.module.Module', initialize weights to zero.\n",
      "     |  ...\n",
      "     |  >>> init = mx.initializer.Zero()\n",
      "     |  >>> module.init_params(init)\n",
      "     |  >>> for dictionary in module.get_params():\n",
      "     |  ...     for key in dictionary:\n",
      "     |  ...         print(key)\n",
      "     |  ...         print(dictionary[key].asnumpy())\n",
      "     |  ...\n",
      "     |  fullyconnected0_weight\n",
      "     |  [[ 0.  0.  0.]]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Zero\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Initializer:\n",
      "     |  \n",
      "     |  __call__(self, desc, arr)\n",
      "     |      Initialize an array\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      desc : InitDesc\n",
      "     |          Initialization pattern descriptor.\n",
      "     |      \n",
      "     |      arr : NDArray\n",
      "     |          The array to be initialized.\n",
      "     |  \n",
      "     |  dumps(self)\n",
      "     |      Saves the initializer to string\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |          JSON formatted string that describes the initializer.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> # Create initializer and retrieve its parameters\n",
      "     |      ...\n",
      "     |      >>> init = mx.init.Normal(0.5)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      "     |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      "     |      >>> init.dumps()\n",
      "     |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      "     |  \n",
      "     |  set_verbosity(self, verbose=False, print_func=None)\n",
      "     |      Switch on/off verbose mode\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      verbose : bool\n",
      "     |          switch on/off verbose mode\n",
      "     |      print_func : function\n",
      "     |          A function that computes statistics of initialized arrays.\n",
      "     |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      "     |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    register(klass)\n",
      "        Registers a custom initializer.\n",
      "        \n",
      "        Custom initializers can be created by extending `mx.init.Initializer` and implementing the\n",
      "        required functions like `_init_weight` and `_init_bias`. The created initializer must be\n",
      "        registered using `mx.init.register` before it can be called by name.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        klass : class\n",
      "            A subclass of `mx.init.Initializer` that needs to be registered as a custom initializer.\n",
      "        \n",
      "        Example\n",
      "        -------\n",
      "        >>> # Create and register a custom initializer that\n",
      "        ... # initializes weights to 0.1 and biases to 1.\n",
      "        ...\n",
      "        >>> @mx.init.register\n",
      "        ... @alias('myinit')\n",
      "        ... class CustomInit(mx.init.Initializer):\n",
      "        ...   def __init__(self):\n",
      "        ...     super(CustomInit, self).__init__()\n",
      "        ...   def _init_weight(self, _, arr):\n",
      "        ...     arr[:] = 0.1\n",
      "        ...   def _init_bias(self, _, arr):\n",
      "        ...     arr[:] = 1\n",
      "        ...\n",
      "        >>> # Module is an instance of 'mxnet.module.Module'\n",
      "        ...\n",
      "        >>> module.init_params(\"custominit\")\n",
      "        >>> # module.init_params(\"myinit\")\n",
      "        >>> # module.init_params(CustomInit())\n",
      "    \n",
      "    sqrt(...)\n",
      "        sqrt(x)\n",
      "        \n",
      "        Return the square root of x.\n",
      "\n",
      "DATA\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "    string_types = (<class 'str'>,)\n",
      "\n",
      "FILE\n",
      "    e:\\devtools\\anaconda3\\envs\\gluon\\lib\\site-packages\\mxnet\\initializer.py\n",
      "\n",
      "\n",
      "Help on class Xavier in module mxnet.initializer:\n",
      "\n",
      "class Xavier(Initializer)\n",
      " |  Returns an initializer performing \"Xavier\" initialization for weights.\n",
      " |  \n",
      " |  This initializer is designed to keep the scale of gradients roughly the same\n",
      " |  in all layers.\n",
      " |  \n",
      " |  By default, `rnd_type` is ``'uniform'`` and `factor_type` is ``'avg'``,\n",
      " |  the initializer fills the weights with random numbers in the range\n",
      " |  of :math:`[-c, c]`, where :math:`c = \\sqrt{\\frac{3.}{0.5 * (n_{in} + n_{out})}}`.\n",
      " |  :math:`n_{in}` is the number of neurons feeding into weights, and :math:`n_{out}` is\n",
      " |  the number of neurons the result is fed to.\n",
      " |  \n",
      " |  If `rnd_type` is ``'uniform'`` and `factor_type` is ``'in'``,\n",
      " |  the :math:`c = \\sqrt{\\frac{3.}{n_{in}}}`.\n",
      " |  Similarly when `factor_type` is ``'out'``, the :math:`c = \\sqrt{\\frac{3.}{n_{out}}}`.\n",
      " |  \n",
      " |  If `rnd_type` is ``'gaussian'`` and `factor_type` is ``'avg'``,\n",
      " |  the initializer fills the weights with numbers from normal distribution with\n",
      " |  a standard deviation of :math:`\\sqrt{\\frac{3.}{0.5 * (n_{in} + n_{out})}}`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  rnd_type: str, optional\n",
      " |      Random generator type, can be ``'gaussian'`` or ``'uniform'``.\n",
      " |  \n",
      " |  factor_type: str, optional\n",
      " |      Can be ``'avg'``, ``'in'``, or ``'out'``.\n",
      " |  \n",
      " |  magnitude: float, optional\n",
      " |      Scale of random number.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Xavier\n",
      " |      Initializer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, rnd_type='uniform', factor_type='avg', magnitude=3)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Initializer:\n",
      " |  \n",
      " |  __call__(self, desc, arr)\n",
      " |      Initialize an array\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      desc : InitDesc\n",
      " |          Initialization pattern descriptor.\n",
      " |      \n",
      " |      arr : NDArray\n",
      " |          The array to be initialized.\n",
      " |  \n",
      " |  dumps(self)\n",
      " |      Saves the initializer to string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          JSON formatted string that describes the initializer.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> # Create initializer and retrieve its parameters\n",
      " |      ...\n",
      " |      >>> init = mx.init.Normal(0.5)\n",
      " |      >>> init.dumps()\n",
      " |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      " |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      " |      >>> init.dumps()\n",
      " |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      " |  \n",
      " |  set_verbosity(self, verbose=False, print_func=None)\n",
      " |      Switch on/off verbose mode\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      verbose : bool\n",
      " |          switch on/off verbose mode\n",
      " |      print_func : function\n",
      " |          A function that computes statistics of initialized arrays.\n",
      " |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      " |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Initializer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Xavier in module mxnet.initializer:\n",
      "\n",
      "class Xavier(Initializer)\n",
      " |  Returns an initializer performing \"Xavier\" initialization for weights.\n",
      " |  \n",
      " |  This initializer is designed to keep the scale of gradients roughly the same\n",
      " |  in all layers.\n",
      " |  \n",
      " |  By default, `rnd_type` is ``'uniform'`` and `factor_type` is ``'avg'``,\n",
      " |  the initializer fills the weights with random numbers in the range\n",
      " |  of :math:`[-c, c]`, where :math:`c = \\sqrt{\\frac{3.}{0.5 * (n_{in} + n_{out})}}`.\n",
      " |  :math:`n_{in}` is the number of neurons feeding into weights, and :math:`n_{out}` is\n",
      " |  the number of neurons the result is fed to.\n",
      " |  \n",
      " |  If `rnd_type` is ``'uniform'`` and `factor_type` is ``'in'``,\n",
      " |  the :math:`c = \\sqrt{\\frac{3.}{n_{in}}}`.\n",
      " |  Similarly when `factor_type` is ``'out'``, the :math:`c = \\sqrt{\\frac{3.}{n_{out}}}`.\n",
      " |  \n",
      " |  If `rnd_type` is ``'gaussian'`` and `factor_type` is ``'avg'``,\n",
      " |  the initializer fills the weights with numbers from normal distribution with\n",
      " |  a standard deviation of :math:`\\sqrt{\\frac{3.}{0.5 * (n_{in} + n_{out})}}`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  rnd_type: str, optional\n",
      " |      Random generator type, can be ``'gaussian'`` or ``'uniform'``.\n",
      " |  \n",
      " |  factor_type: str, optional\n",
      " |      Can be ``'avg'``, ``'in'``, or ``'out'``.\n",
      " |  \n",
      " |  magnitude: float, optional\n",
      " |      Scale of random number.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Xavier\n",
      " |      Initializer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, rnd_type='uniform', factor_type='avg', magnitude=3)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Initializer:\n",
      " |  \n",
      " |  __call__(self, desc, arr)\n",
      " |      Initialize an array\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      desc : InitDesc\n",
      " |          Initialization pattern descriptor.\n",
      " |      \n",
      " |      arr : NDArray\n",
      " |          The array to be initialized.\n",
      " |  \n",
      " |  dumps(self)\n",
      " |      Saves the initializer to string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          JSON formatted string that describes the initializer.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> # Create initializer and retrieve its parameters\n",
      " |      ...\n",
      " |      >>> init = mx.init.Normal(0.5)\n",
      " |      >>> init.dumps()\n",
      " |      '[\"normal\", {\"sigma\": 0.5}]'\n",
      " |      >>> init = mx.init.Xavier(factor_type=\"in\", magnitude=2.34)\n",
      " |      >>> init.dumps()\n",
      " |      '[\"xavier\", {\"rnd_type\": \"uniform\", \"magnitude\": 2.34, \"factor_type\": \"in\"}]'\n",
      " |  \n",
      " |  set_verbosity(self, verbose=False, print_func=None)\n",
      " |      Switch on/off verbose mode\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      verbose : bool\n",
      " |          switch on/off verbose mode\n",
      " |      print_func : function\n",
      " |          A function that computes statistics of initialized arrays.\n",
      " |          Takes an `NDArray` and returns an `str`. Defaults to mean\n",
      " |          absolute value str((abs(x)/size(x)).asscalar()).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Initializer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(init.Xavier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "* 使用 Gluon 可以更简洁地实现模型。\n",
    "* 在 Gluon 中，`data`模块提供了有关数据处理的工具，`nn`模块定义了大量神经网络的层，`loss`模块定义了各种损失函数。\n",
    "* MXNet 的`initializer`模块提供了模型参数初始化的各种方法。\n",
    "\n",
    "\n",
    "## 练习\n",
    "\n",
    "* 如果将`l = loss(net(X), y)`替换成`l = loss(net(X), y).mean()`，我们需要将`trainer.step(batch_size)`相应地改成`trainer.step(1)`。这是为什么呢？\n",
    "> l为小批量的损失，trainer.step(batch_size)在更新权重w的时候步幅为learing_rate/batch_size.l为小批量的损失，trainer.step(batch_size)在更新权重w的时候步幅为learing_rate/batch_size.\n",
    "如果先求过均值了，那l就是小批量的平均损失, 更新权重的时候就不用再除以batch_size了。\n",
    "可以试着把learing_rate改小比如0.003，然后迭代次数改大点num_epochs = 10.\n",
    "对比trainer.step(1)和trainer.step(batch_size), 可以明显观察到前者收敛的更快，因为步幅更大。\n",
    "如果先求过均值了，那l就是小批量的平均损失, 更新权重的时候就不用再除以batch_size了。\n",
    "可以试着把learing_rate改小比如0.003，然后迭代次数改大点num_epochs = 10.\n",
    "对比trainer.step(1)和trainer.step(batch_size), 可以明显观察到前者收敛的更快，因为步幅更大。\n",
    "* 查阅 MXNet 文档，看看`gluon.loss`和`init`模块里提供了哪些损失函数和初始化方法。\n",
    "> help(gluon.loss)         \n",
    "help(init)\n",
    "* 如何访问`dense.weight`的梯度？\n",
    "> dense.weight.grad()\n",
    "\n",
    "\n",
    "## 扫码直达[讨论区](https://discuss.gluon.ai/t/topic/742)\n",
    "\n",
    "![](../img/qr_linear-regression-gluon.svg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
